<!doctype html>
<html lang="en">
<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC"
          crossorigin="anonymous">
    
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet">
  
    <link href="https://fonts.googleapis.com/css2?family=Kreon:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style/style.css">

    <title>GPTAlly</title>
</head>
<body>

    <nav class="navbar navbar-light bg-light-nav-custom navbar-expand-lg">
        <div class="container-fluid">
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarText" aria-controls="navbarText" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarText">
                <ul class="navbar-nav me-auto mb-2 mb-lg-0 w-100">
                    <li class="nav-item">
                        <a class="nav-link active" href="index.html">Main</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="safety_evaluation.html">Safety Evaluation</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="decision_making.html">Decision Making</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="functions.html">Robot Engine</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
      <!--
      <div class="alert alert-danger alert-dismissible fade show alert-sticky" role="alert">
        <strong>Website still in progress, </strong> it will be final on the 24th of June !
        <button type="button" class="btn-close" data-bs-dismiss="alert" aria-label="Close"></button>
      </div>
      -->
    <div class="container container-box-main border rounded p-4 mt-4 ">
        <div class="row justify-content-center">
            <div class="col-auto">
                <h1>GPTAlly</h1>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col-auto text-center">
                <h4> A Safety-Oriented System for Human-Robot Collaboration based on Foundation Models</h4>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col-auto text-center">
                <h6><span style="color: rgb(79, 79, 239);"> Brieuc Bastin<sup>1</sup>, Shoichi Hasegawa<sup>2</sup>, Jorge Solis<sup>3</sup>, Renaud Ronsse<sup>1</sup>, Benoit Macq<sup>1</sup>, Lotfi El Hafi<sup>2</sup>,  Gustavo Alfonso Garcia Ricardez<sup>2,*</sup>, and Tadahiro Taniguchi<sup>2,4</sup></span></h6>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col-auto">
                <h7><sup>1</sup>Universite catholique de Louvain, <sup>2</sup>Ritsumeikan University, <sup>3</sup>Karlstad University, <sup>4</sup>Kyoto University</h7>
            </div>
        </div>
        <div class="row justify-content-center mt-3">
            <div class="col-auto">
                <a href="https://github.com/Axtiop/GPTAlly_codebase.git" class="btn btn-light btn-with-logo border mb-2">
                        <span>GitHub</span>
                        <i class="fab fa-github"></i> <!-- GitHub icon -->
                </a>
            </div>
            <div class="col-auto">
                <button class="btn btn-light btn-with-logo border">
                    <span>Paper</span>
                    <i class="fas fa-file-pdf"></i> <!-- GitHub icon -->
                </button>
            </div>
            <div class="col-auto">
                <button class="btn btn-light btn-with-logo border">
                    <span>Video</span>
                    <i class="fas fa-video"></i> <!-- GitHub icon -->
                </button>
            </div>
        </div>
    </div>

    <div class="container p-4 mt-4 container_global">
        <div class="row justify-content-center">
            <div class="col-auto">
                <video src="Figures/Video_v2.mp4" class="video_global" controls loop>
                    <source type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>
        </div>
    </div>
    <div class="container container-box-main border rounded p-4 mt-4 ">
        <div class="row justify-content-center">
            <div class="col-auto">
                <h3>Abstract</h3>
            </div>
        </div>
        <!--
        <div class="row">
            <div class="col-auto">
                <p class="text-justify lead fs-6">We are aiming for Society 5.0 which emphasizes improving workplace quality of life through AI and robotics. However, current robots lack human-like situational understanding and often rely on pre-programmed tasks or supervised learning. Additionally, t here is a need for safety metrics that consider users' subjective safety perceptions. This thesis introduces GPTAlly, a system for safe human-robot collaboration using Large Language Models (LLMs) and Visual Language Models (VLMs). LLMs help infer users' subjective safety perceptions in collaborative tasks, influencing a Safety Index algorithm that adjusts safety evaluations. The system ensures robots stop to prevent harmful collisions and uses an LLM-based coding paradigm to determine subsequent actions, either autonomously or as per user preferences. The actions are implemented by an LLM, which shapes robotic arm trajectories by interpreting the natural language instructions of the user to suggest 3D poses. A user study compares safety perception scaling factors from GPT-4 with participants' estimates. The study also evaluates user satisfaction with the changes in robot behavior. The accuracy of the streamlined coding paradigm is evaluated through contextual experiments by varying the number of conditions processed by the LLM as well as paraphrasing the conditions. The satisfaction with the trajectories shaped from 3D poses is assessed through another user study. The study finds that LLMs effectively integrate human safety perceptions, with GPT-4's estimations closely matching user responses and participants expressing satisfaction with behavior changes. However, the coding paradigm's contextual accuracy can be below 50%. Finally, the robotic arm trajectories found that users preferred trajectories shaped by their natural language inputs over uninfluenced ones.</p>
            </div>
        </div>
        -->
    <div class="row">
        <div class="col-auto">
            <p class="text-justify lead fs-6">As robots increasingly integrate into the workplace, Human-Robot Collaboration (HRC) has become increasingly important.
                However, most HRC solutions are based on pre-programmed tasks and use fixed safety parameters, which keeps humans out of the loop.
                To overcome this, HRC solutions that can easily adapt to human preferences during the operation as well as their safety precautions considering the familiarity with robots are necessary.
                In this paper, we introduce GPTAlly, a novel safety-oriented system for HRC that leverages the emerging capabilities of Large Language Models (LLMs).
                GPTAlly uses LLMs to 1) infer users' subjective safety perceptions to modify the parameters of a Safety Index algorithm; 2) decide on subsequent actions when the robot stops to prevent unwanted collisions; and 3) re-shape the robot arm trajectories based on user instructions.
                We subjectively evaluate the robot's behavior by comparing the safety perception of GPT-4 to the participants.
                We also evaluate the accuracy of natural language-based robot programming of decision-making requests.
                The results show that GPTAlly infers safety perception similarly to humans, and achieves an average of 80% of accuracy in decision-making, with few instances under 50%.</p>
        </div>
    </div>
    </div>


    <div class="container mt-2 mb-2 border rounded p-4 container-box-main">
        <div class="row justify-content-around">
            <div class="col text-center">
                <img id="exp_image" src="Figures/main_figure_vf2.jpg" class="img-fluid" alt="Responsive image">
            </div>
        </div>
    </div>
    <div class="container-red container container-box-main border rounded p-4 mt-4 ">
        <div class="row justify-content-center">
            <div class="col-auto">
                <h3>Safety Evaluation</h3>
            </div>
        </div>
        <div class="row justify-content-center mt-3">
            <div class="col-auto">
                <p class="text-justify lead fs-6"><strong>The first goal</strong> is to demonstrate the capacity of <strong>LLMs</strong> to estimate <strong>human safety perceptions</strong> through a <strong>scaling factor</strong> (<strong>GPT<f><sub>f</sub></f></strong>). This is achieved by comparing the results from <strong>GPT-4</strong> to the answers from a <strong>user study</strong> with the prompts listed <a href="safety_evaluation.html" class="text-warning"><strong>here.</strong></a></p>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col text-center">
                <img id="exp_image_GPT" src="Figures/Exp1_Results_1_v4.png" alt="Responsive image">
            </div>
        </div>
        <div class="row mt-5 mb-2 text-center">
            <div class="col text-center">
                <p class="text-justify lead fs-6"><strong>Through the experiment detailed</strong> <a href="safety_evaluation.html" class="text-warning"><strong>here</strong></a>, the next goal is to demonstrate how <strong>LLMs</strong> can integrate <strong>human perception of safety</strong> into <strong>safety assessments</strong>. This is achieved by analyzing the <strong>reaction</strong> and <strong>efficiency</strong> of the robot with different <strong>GPT<f><sub>f</sub></f></strong> across a spectrum of <strong>scenarios</strong>, ranging from easy to challenging. The following results come from the <strong>easier experiment.</strong></p>
            </div>
        </div>
        <div class="row justify-content-center align-items-center">
            <div class="col-md-6 col-sm-12 text-center mb-5">
                <img src="Figures/Exp1_1_1_with_images.png" class="img-fluid" alt="Responsive image">
            </div>
            <div class="col-md-6 col-sm-12 text-center mb-5">
                <img src="Figures/table.png" class="img-fluid" alt="Responsive image">
            </div>
        </div>
        <div class="row mb-2 text-center">
            <div class="col text-center">
                <p class="text-justify lead fs-6"><strong>In the following qualitative assessment</strong>, the satisfaction of the user with the behavior of the robot with different input prompts is tested through a <strong>user study</strong>. They are requested to assess their level of satisfaction on a scale of <strong>1 to 5</strong> (1 is very unsatisfied and 5 is very satisfied) regarding the new behavior of the robot in comparison to its <strong>neutral behavior</strong> (where <strong>GPT<f><sub>f</sub></f> = 1.0</strong>). <strong>GPT<f><sub>f</sub></f> = 0.5</strong> means that the user is very confident around robots and <strong>GPT<f><sub>f</sub></f> = 1.5</strong> means that the user is very afraid of robots.</p>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col text-center">
                <img id="exp_image_GPT" src="Figures/Exp1_Results_2_v4.png" alt="Responsive image">
            </div>
        </div>
    </div>
    

    <div class="container-green container container-box-main border rounded p-4 mt-4 ">
        <div class="row justify-content-center">
            <div class="col-auto">
                <h3>Decision Making</h3>
            </div>
        </div>
        <div class="row justify-content-center mt-3">
            <div class="col-auto">
                <p class="text-justify lead fs-6">Three distinct tests are made to evaluate the viability of using <strong>LLMs</strong> as a <strong>streamlined coding paradigm</strong>. The first one consists of changing the <strong>natural language</strong> used to express the same condition on the input and thereby assessing the condition <strong>paraphrasing</strong>. Then, with language inputs that follow a similar structure, namely <strong>condition adjustment</strong>, different conditions are tested. The final step is to assess the <strong>scalability</strong> of the condition (<strong>condition scalability</strong>), gauging the system's capability to effectively manage increasingly intricate conditions. An extensive description of the experiment can be found <a href="decision_making.html" class="text-warning"><strong>here.</strong></a></p>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col text-center">
                <img id="exp_image_GPT" src="Figures/Exp3_Results_v2.png" alt="Responsive image">
            </div>
        </div>
    </div>
    
    <div class="container-black container container-box-main border rounded p-4 mt-4 ">
        <div class="row justify-content-center">
            <div class="col-auto">
                <h3>Robot Controller: Withdrawal</h3>
            </div>
        </div>
        <div class="row justify-content-center mt-3">
            <div class="col-auto">
                <p class="text-justify lead fs-6">The objective of this experiment is to evaluate the use of <strong>LLMs</strong> to shape <strong>robotic arm trajectories</strong>. The methods' performance was evaluated through a <strong>user study</strong>, where a total of 150 data points were collected from each of the 30 participants. Each participant was asked to rate the withdrawal methods on a <strong>1-5 Likert scale</strong>, based on a given <strong>natural language input</strong>. The following figure summarizes the distribution of the answers for each method. <strong>Withdrawal 1</strong> represents the withdrawal method proposed by <a href="https://ieeexplore.ieee.org/document/6696490" class="text-warning"><strong>Garcia et al.</strong></a>, <strong>Withdrawal 2</strong> is the same method with the parking position modified by <strong>GPT-4</strong>, and <strong>Withdrawal 3</strong> is the method where <strong>GPT-4</strong> suggests a new withdrawal position directly.</p>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col text-center">
                <img id="exp_image_GPT" src="Figures/withdrawal_v3.png" alt="Responsive image">
            </div>
        </div>
        <div class="row mt-5 mb-2 text-center">
            <div class="col text-center">
                <p class="text-justify lead fs-6">In the same user study, participants were asked to select their <strong>preferred withdrawal method</strong> if they were in the user's situation. On the left, the figure displays the <strong>average satisfaction level</strong>, ranging from 1 (very unsatisfied) to 5 (very satisfied). A <strong>Kruskal–Wallis test</strong> and two <strong>Mann–Whitney U tests</strong> were conducted to examine the differences between the means. In the same user study, participants were asked to select their <strong>favorite withdrawal method</strong> if they were in the user's situation, as shown on the right. Unlike the previous question where they had to assess their satisfaction, they were asked to decide on only one <strong>favorite</strong>.</p>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col-md-6 col-sm-12 text-center mb-5">
                <img id="exp_image" src="Figures/withdrawal_r2_v3.png" class="img-fluid" alt="Responsive image">
            </div>
            <div class="col-md-6 col-sm-12 text-center mb-5">
                <img id="exp_image" src="Figures/withdrawal_choices_v3.png" class="img-fluid" alt="Responsive image">
            </div>
        </div>
    
        <div class="row mt-5 mb-2 text-center">
            <div class="col text-center">
                <p class="text-justify lead fs-6">The users were also asked to assess the significance of each factor for their previous answers. The following figure displays the distribution of their responses. There were three factors they had to evaluate: <strong>safety</strong>, which refers to the robot moving to a <strong>safer location</strong>; <strong>compliance</strong>, which indicates the robot following the user's command; and <strong>human-like behavior</strong>, which involves the robot exhibiting behavior resembling that of a human.</p>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col text-center">
                <img id="exp_image_GPT" src="Figures/withdrawal_factors_v3.png" alt="Responsive image">
            </div>
        </div>
        <div class="row mt-5 mb-2 text-center">
            <div class="col text-center">
                <p class="text-justify lead fs-6">Finally, the distributions from the users were divided into three groups: <strong>students from UCLouvain</strong> who did not receive an <strong>engineering education</strong> (<strong>UCLouvain-Other</strong>), students from <strong>UCLouvain</strong> who did receive an <strong>engineering education</strong> (<strong>UCLouvain-Engineer</strong>), and students from <strong>Ritsumeikan</strong> who received engineering education (<strong>Ritsumeikan-Engineer</strong>). <strong>UCLouvain</strong> students study in <strong>Belgium</strong>, while <strong>Ritsumeikan</strong> students study in <strong>Japan</strong>.</p>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col text-center">
                <img id="exp_image_GPT" src="Figures/withdrawal_dataset_dist_v3.png" alt="Responsive image">
            </div>
        </div>
    </div>
    
    <div class="container-black container container-box-main border rounded p-4 mt-4 mb-4 ">
        <div class="row justify-content-center">
            <div class="col-auto">
                <h3><strong>Robot Controller: Change Objective</strong></h3>
            </div>
        </div>
        <div class="row justify-content-center mt-3">
            <div class="col-auto">
                <p class="text-justify lead fs-6">With the same objective of evaluating the use of <strong>LLMs</strong> to shape <strong>trajectories</strong>, the change in objective is evaluated by comparing the responses provided by <strong>GPT-4</strong> and users in a <strong>user study</strong> when given the same instructions, such as "<strong>Pick a block between me and the robot</strong>". The user ("<strong>Me</strong>") is positioned in (0.7, 0.0) and the robot is positioned in (0.1, 0.0). In red is the answer from <strong>GPT-4</strong> and the frequency indicates the number of times a user chose this block relative to the maximum number of times any block was chosen. The experiment is explained more in detail <a href="functions.html" class="text-warning"><strong>here.</strong></a></p>
            </div>
        </div>
        <div class="row mt-1 mb-2 text-center">
            <div class="col text-center">
                <p class="text-justify lead fs-6">On the left side, the prompt provided to both the user and <strong>GPT-4</strong> is "<strong>Take a block that is close to me</strong>". On the right side, the prompt is "<strong>Take a block that is close to the robot</strong>".</p>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col-md-6 col-sm-12 text-center mb-5">
                <img id="exp_image" src="Figures/CO_4_v2.png" class="img-fluid" alt="Responsive image">
            </div>
            <div class="col-md-6 col-sm-12 text-center mb-5">
                <img id="exp_image" src="Figures/CO_7_v2.png" class="img-fluid" alt="Responsive image">
            </div>
        </div>
        <div class="row mt-5 mb-2 text-center">
            <div class="col text-center">
                <p class="text-justify lead fs-6">On the left side, the prompt is "<strong>Take a block on the left</strong>", and on the right side, the prompt is "<strong>Take a cube on the right</strong>".</p>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col-md-6 col-sm-12 text-center mb-5">
                <img id="exp_image" src="Figures/CO_1_v2.png" class="img-fluid" alt="Responsive image">
            </div>
            <div class="col-md-6 col-sm-12 text-center mb-5">
                <img id="exp_image" src="Figures/CO_2_v2.png" class="img-fluid" alt="Responsive image">
            </div>
        </div>
        <div class="row mt-5 mb-2 text-center">
            <div class="col text-center">
                <p class="text-justify lead fs-6">On the left side, the prompt is "<strong>Take a block far from the robot</strong>", and on the right side, the prompt is "<strong>Take one of the furthest block from the robot</strong>".</p>
            </div>
        </div>
        <div class="row justify-content-center">
            <div class="col-md-6 col-sm-12 text-center mb-5">
                <img id="exp_image" src="Figures/CO_8_v2.png" class="img-fluid" alt="Responsive image">
            </div>
            <div class="col-md-6 col-sm-12 text-center mb-5">
                <img id="exp_image" src="Figures/CO_9_v2.png" class="img-fluid" alt="Responsive image">
            </div>
        </div>
    </div>
    
    
<!-- Bootstrap Bundle JS -->
<script
        src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>

<!-- Chart.js -->
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    

<!-- <script src="scripts/main.js"></script> -->


</body>
</html>
